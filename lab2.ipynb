{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"lab2.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"uN6Z8jBlIXmP"},"source":["# Algorithmic Data Science : Lab 2\n","\n","## Investigating the run-time of sorting algorithms\n","\n","We have claimed that the insertion_sort algorithm runs in:\n","\n","$$c_a n^2$$\n","\n","for a fixed constant $c_a$ when the length $n$ of the list is large. This is an empirical claim, i.e., something which can be verified.  \n","\n","1) Design experiments to verify/falsify it by obtaining code for the algorithm and plotting the run-time for lists of different lengths, and analysing the results. \n","\n","2) Can you estimate the constant $c_a$ for your computer? Compare your value of $c_a$ with those of other students. \n","\n","3) How accurate can you make $c_a$?  What is the standard deviation / error in your measurements?\n","\n","4) You should have been using lists that lead to the worst case scenario. What happens if you instead use lists that lead to average scenarios, or best case scenarios?\n","\n","5) Repeat your experiments while your computer is heavily loaded (e.g. running some video processing in the background), and compare the results.\n","\n","Now repeat the exercise for the merge_sort algorithm, which we theoretically expect to run in\n","\n","$$c_bn\\log(n)$$\n","\n","for a fixed constant $c_b$ when the length of the list is large.\n"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"qA49AuPSIXmT"},"source":["## Tips"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"mCBrt5i6IXmU"},"source":["How will you know you have a quadratic curve $y=c_a x^2$ for insertion_sort and not a curve of $x$ to some other power, $y=c_a x^\\alpha$? For this more general case, taking logs of both sides of the equation gives:\n","$$\\log(y) = \\log(c_a) + \\alpha \\log(x)$$\n","So you should plot the log of the time taken against the log of the length of the list - assuming the function is indeed of the form $y=c_a x^\\alpha$, the log-log plot will give you a straight line, and the gradient of this straight line will be $\\alpha$ and the $y$ intercept will be $\\log(c_a)$."]},{"cell_type":"markdown","metadata":{"id":"oZLgbgM9IXmV"},"source":["Estimate the gradient and intercept of the log-log plot using a function from a stats library, e.g. *scipy*."]},{"cell_type":"markdown","metadata":{"id":"iOAvdJMdIXmV"},"source":["If you find $\\alpha$ is not that close to 2, it's because the lists you're considering are not long enough for the time complexity to be behaving the way it does asymptotically for large $n$: in that case, try a plot using longer lists."]},{"cell_type":"markdown","metadata":{"id":"79_4dNaGIXmW"},"source":["For mergesort, we're testing whether the run-time goes like $c_b n\\log n$.  For that case we cannot (sensibly) log both sides.  However we can use a transformation $x=n \\log n$.  If we plot $y$=time-taken against this $x$ then we should get a straight line graph with gradient $c_b$ and $y$-intercept $\\approx$ 0."]},{"cell_type":"code","metadata":{"id":"OtT5JESBIXmX"},"source":[""],"execution_count":null,"outputs":[]}]}